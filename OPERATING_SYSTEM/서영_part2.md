### 🔍 8. 뮤텍스와 세마포어의 차이점은 무엇인가요?
뮤텍스와 세마포어 모두 상호 배제를 위해 사용되지만, 락의 소유권과 동시 접근 가능 개수에서 차이가 있습니다. 
뮤텍스는 락을 획득한 단 하나의 스레드만 해제할 수 있는 소유권이 있는 락으로, 항상 하나의 스레드만 임계 영역에 접근할 수 있습니다. 
반면, 세마포어는 락의 소유권이 없고 사용 가능한 자원의 갯수만큼 여러 스레드가 동시에 접근 가능한 구조로, 
하나 이상의 자원 동기화에도 사용될 수 있습니다.

#### ❓ 이진 세마포어와 뮤텍스의 차이에 대해 설명해 주세요.
이진 세마포어는 값이 0 또는 1만 가능해 뮤텍스와 유사하지만, 
소유권 개념이 없기 때문에 다른 스레드가 해제할 수 있어 동기화가 깨질 수 있는 위험이 존재합니다. 

#### ❓ Lock을 얻기 위해 대기하는 프로세스들은 Spin Lock 기법을 사용할 수 있습니다. 이 방법의 장단점은 무엇인가요? 단점을 해결할 방법은 없을까요?
Spin Lock은 락을 얻기 위해 루프를 도는 방식으로 context switching 비용이 없어 짧은 시간 대기에는 적합합니다. 
하지만 CPU를 낭비하는 단점이 있어 일정 시간 busy-waiting 상태로 두었다가 커널 락으로 전환하는 혼합 락으로 보완할 수 있습니다.

#### ❓뮤텍스와 세마포어 모두 커널이 관리하기 때문에, Lock을 얻고 방출하는 과정에서 시스템 콜을 호출해야 합니다. 이 방법의 장단점이 있을까요? 단점을 해결할 수 있는 방법은 없을까요?
커널 기반 락은 안정성은 높지만 시스템 콜 호출로 인한 오버헤드가 발생해 성능이 저하될 수 있습니다. 
이를 해결하기 위해 사용자 모드에서 루프를 돌며 기다리는 스핀락이나 짧은 시간동안 스핀락으로 시도하고 실패하면 
커널락으로 전환하는 혼합락을 사용할 수 있습니다. 
또한 대부분의 락 처리를 유저 공간에서 처리하고 실제 충돌 시에만 커널에 진입하는 Futex를 사용할 수 도 있습니다.

---
### 🔍 9. Deadlock 에 대해 설명해 주세요.
2개 이상의 작업이 동시에 이루어지는 경우, 한 작업이 공유 자원을 사용하고 있을 때 다른 작업도 
그 공유 자원을 사용하기 위해 기다리면서 작업을 수행하지 못하는 상황을 데드락, 교착 상태라고 합니다.

#### ❓ Deadlock 이 동작하기 위한 4가지 조건에 대해 설명해 주세요.
- 상호 배제: 한 프로세스가 사용하는 자원이 다른 프로세스와 공유할 수 없는 배타적 자원일 때 교착 상태가 발생한다.
- 비선점: 한 프로세스가 자원을 사용하고 있으면 다른 프로세스가 강제로 가져올 수 없을 때 교착 상태가 발생한다.
- 점유 대기: 프로세스가 어떤 자원을 사용하고 있을 때 다른 자원을 기다릴 때 교착 상태가 발생한다.
- 환형 대기: 점유와 대기를 하는 프로세스 간의 관계가 원을 이루고 서로 양보하지 않을 때 교착 상태가 발생한다.

#### ❓ 그렇다면 3가지만 충족하면 왜 Deadlock 이 발생하지 않을까요?
하나라도 깨지면 데드락 상황이 발생하지 않습니다. 예를 들어, 자원 선점이 가능하면 대기하지 않고 강제로 빼앗아서
데드락 상황이 발생하지 않습니다.

#### ❓ 어떤 방식으로 예방할 수 있을까요?
주로 사용하는 방식은 교착 상태를 검출하고 회복하는 방법입니다. 
어떠한 제약도 걸지 않고 자원 할당 그래프를 모니터링하면서 교착 상태가 발생하는지 살펴보는 방식입니다.
한 프로세스가 오랜 시간 동안 작업이 끝나지 않으면 이를 교착 상태라고 간주하고 회복하는 단계를 거칩니다.
4가지 조건이 발생하지 않도록 예방하거나 회피하는 방법을 사용할 수 있지만 많은 자원이 낭비되기 때문에
현실적으로 자주 사용하지는 않습니다. 

#### ❓ 왜 현대 OS는 Deadlock을 처리하지 않을까요?
빈번히 발생하는 이벤트가 아니기 때문에 미연에 방지하기 위해 훨씬 더 많은 오버헤드를 들이는것이 비효율적이기 때문입니다.

#### ❓ Wait Free와 Lock Free를 비교해 주세요.
Wait Free는 모든 스레드가 일정한 시간 내에 작업을 완료할 수 있도록 설계되어 있으며, 무한 대기가 발생하지 않습니다. 
시간 제한이 필요한 실시간 시스템에 적합합니다. 
Lock Free는 특정 작업을 동시에 여러 쓰레드가 호출했을 때 적어도 하나는 완료해서 반환하도록 설계되어 있습니다. 
모든 스레드의 성공을 보장하지는 않고 특정 스레드가 무한히 대기 할 수 있습니다.

---
### 🔍 10. 프로그램이 컴파일 되어, 실행되는 과정을 간략하게 설명해 주세요.
개발자가 코드를 작성하면 컴파일러가 소스코드를 바이트코드 또는 오브젝트 코드로 변환합니다. 
그 후 여러 파일과 라이브러리를 하나의 실행파일로 합치는 링크 과정, 운영체제가 실행 파일을 메모리에 올리는
로딩 과정을 순서대로 거칩니다. cpu는 메모리에 올라온 프로그램을 실행시킴니다. 

#### ❓ 링커와, 로더의 차이에 대해 설명해 주세요.
링커는 여러 오브젝트 파일과 라이브러리를 하나의 실행 파일로 합치는 과정입니다. 
그 과정에서 코드와 데이터에 메모리를 할당하며 컴파일 시점에 발생합니다.
로더는 프로그램을 메모리에 올리는 역할이며 실행 시간에 일어납니다.

#### ❓ 컴파일 언어와 인터프리터 언어의 차이에 대해 설명해 주세요.
컴파일 언어는 실행 전에 코드 전체를 기계어로 번역하는 과정을 거친 후 실행됩니다. 
컴파일 시간에 이루어지고 실행 시작 속도는 느리지만 실행 속도는 빠릅니다. c, c++이 컴파일 언어입니다.
인터프리터 언어는 실행 시작 후에 한 줄씩 기계어로 번역 과정을 거쳐 실행됩니니다. 
런타임에 이루어지고 실행 속도는 느리지만 실행 시작 속도는 빠릅니다. 자바스크립트가 인터프리터 언어입니다.

#### ❓ JIT에 대해 설명해 주세요.
JIT(Just-In-Time) 컴파일은 컴파일 언어와 인터프리터 언어의 장점을 결합한 방식입니다. 
실행 시작 후에 인터프리터 방식으로 기계어 코드를 생성하면서 자주 쓰이는 메서드를 캐싱합니다.
따라서 실행 속도가 느린 인터프리터의 단점을 어느 정도 보완할 수 있습니다. 컴파일러지만 런타임에 실행된다는 특징이 있습니다.

#### ❓ 본인이 사용하는 언어는, 어떤식으로 컴파일 및 실행되는지 설명해 주세요.
자바는 컴파일 방식과 인터프리터 방식을 모두 사용하고 있습니다.
자바 파일은 자바 컴파일러를 통해 클래스 파일로 컴파일이 이루어집니다. 
JVM의 실행 엔진 내에 있는 자바 인터프리터를 통해 바이트 코드를 특정 환경의 기계어로 번역해서 실행합니다. 

#### ❓ Python 같은 언어는 CPython, Jython, PyPy등의 다양한 구현체가 있습니다. 각각은 어떤 차이가 있을까요? 또한, 실행되는 과정 또한 다를까요?
실행 과정은 구현체에 따라 달라집니다.  CPython은 파이썬의 기본 구현체 입니다.  
파이썬 코드를 바이트 코드로 컴파일 후 CPuthon 인터프리터가 이를 해석해서 실행합니다. 
Jython은 파이선을 자바 바이트코드로 변환하며 JVM 위에서 실행됩니다. 
PyPy은 파이썬으로 작성된 고속 실행 구현체입니다. JIT 컴파일러를 사용합니다.

#### ❓ 우리는 흔히 fork(), exec() 시스템 콜을 사용하여 프로세스를 적재할 수 있다고 배웠습니다. 로더의 역할은 이 시스템 콜과 상관있는 걸까요? 아니면 다른 방식으로 프로세스를 적재할 수 있는 건가요?
exec()은 새로운 프로그램을 메모리에 적재하고 실행하는 시스템 콜입니다. 
시스템 콜을 호출하면 커널이 로더를 호출하여 프로그램을 메모리에 올라갈 수 있습니다.

---
### 🔍 11. IPC가 무엇이고, 어떤 종류가 있는지 설명해 주세요.
IPC(Inter-Process Communication)는 서로 다른 프로세스 간에 데이터를 주고 받는 것을 말합니다. 운영체제는 각 프로세스에 독립적인 메모리를 할당하기 때문에, 프로세스끼리는 메모리를 공유하지 못합니다. 그래서 프로세스간에 데이터를 주고 받으려면 IPC가 필요합니다. 대표적으로는 Shared Memory, Message Queue 방식이 있습니다. 

#### ❓ Shared Memory가 무엇이며, 사용할 때 유의해야 할 점에 대해 설명해 주세요.
Shared Memory(공유 메모리)는 여러 프로세스가 동시에 접근 가능한 메모리 공간을 만들어, 그 안에서 데이터를 주고받도록 하는 방식입니다.
커널을 거치지 않고, 사용자 공간에서 직접 데이터 접근이 가능해지기 때문에 빠릅니다. 하지만 데이터 간에 동기화가 필요합니다.

#### ❓ 메시지 큐는 단방향이라고 할 수 있나요?
기본적으로 메시지 큐는 단방향입니다. 하나의 메시지 큐는 보내는 쪽과 받는 쪽이 명확하게 나뉘어져 있습니다. 양방향이 필요한 경우 메시키 큐 2개를 사용해야합니다. 

---
### 🔍  12. Thread Safe 하다는 것은 어떤 의미인가요?  
Thread Safe 하다는 것은 여러 스레드가 동시에 같은 변수나 객체 등에 접근하더라도 실행 결과가 의도한대로 나오는 것을 말합니다. 즉 데이터의 일관성과 무결성이 유지됨을 의미합니다. Thread Safe하지 않다면, 예상치 못한 결과나 버그가 발생할 수 있습니다.

#### ❓ Thread Safe 를 보장하기 위해 어떤 방법을 사용할 수 있나요?
동기화, 불변 객체, ThreadLocal, 원자 클래스 사용 등이 있습니다. 동기화 방법은 락을 걸어서 임계 구역에 하나의 스레드만 접근 가능하게 합니다. ThreadLocal은 각 스레드마다 별도의 변수를 가져 ThreadSafe를 유지할 수 있습니다.

#### ❓ Peterson's Algorithm 이 무엇이며, 한계점에 대해 설명해 주세요.
피터슨 알고리즘은 임계 구역에 오로지 하나의 스레드의 접근을 보장하는 알고리즘입니다. 단 두개의 스레드가 있을때만 이 알고리즘을 사용할 수 있어 다중 스레드로 확장하기 어렵습니다. 또한 busy waiting 문제가 발생해 cpu 자원이 낭비됩니다.

#### ❓ Race Condition 이 무엇인가요?
2개 이상의 스레드가 동시에 공유 자원에 접근하여 접근 순서에 따라 실행 결과가 예상치 못하게 바뀌는 상황을 의미합니다.

#### ❓ Thread Safe를 구현하기 위해 반드시 락을 사용해야 할까요? 그렇지 않다면, 어떤 다른 방법이 있을까요?
꼭 락을 사용할 필요는 없습니다. 불변객체나 ThreadLocal등 락을 사용하지 않고도 Thread Safe한 상황을 구현할 수 있습니다.

---
### 🔍 13. Thread Pool, Monitor, Fork-Join에 대해 설명해 주세요.
- Thread Pool: 스레드를 미리 만들어두고 재사용하는 방식입니다. 새로운 작업이 들어오면 스레드 풀에 있는 스레드를 할당하고 작업이 끝나면 다시 스레드 풀로 반환됩니다.
  스레드 생성과 소멸 비용을 줄여 자원 낭비를 방지합니다.
- Monitor: 임계 구역을 보호하기 위한 동기화 객체입니다. 한 번의 하나의 스레드만 공유 자원에 접근할 수 있고 다른 스레드는 대기해야합니다.
- Fork-Join: 작업을 작은 단위로 나누어 병렬적으로 처리하고 결과를 합치는 방식입니다.
  

#### ❓ Thread Pool을 사용한다고 가정하면, 어떤 기준으로 스레드의 수를 결정할 것인가요?
cpu 바운드 작업은 계산 중심이기 때문에 코어수와 스레드를 같게 하는 것이 효율적입니다. I/O 바운드 작업은 데이터를 읽고 쓰는 대기 시간이 있기 때문에 코어수보다 스레드를 더 많이 할용할 수 있습니다.
하지만 스레드 수가 너무 많으면 비효율적이기 때문에 작업의 특성과 하드웨어의 특성에 맞게 최적의 스레드 갯수를 찾느 것이 중요합니다.

#### ❓ 어떤 데이터를 정렬 하려고 합니다. 어떤 방식의 전략을 사용하는 것이 가장 안전하면서도 좋은 성능을 낼 수 있을까요?
데이터 특성(정렬 상태, 크기, 안정성, 메모리)을 고려해서 적절한 알고리즘을 선택하는 것이 가장 안전하고 좋은 성능을 내는 전략입니다.
데이터 크기가 작고 거의 정렬된 상태면 삽입 정렬이 빠르고 효율적입니다.
대용량 데이터면서 안정성이 필요한 경우  Merge Sort나 TimSort처럼 안정 정렬을 선택합니다.
평균 성능이 중요하고 안정성은 필요 없다면 Quick Sort가 가장 빠른 편입니다.
Java의 Arrays.sort()는 primitive에 QuickSort 기반, 객체에 TimSort를 사용하고 있습니다.

---

### 🔍  14. 캐시 메모리 및 메모리 계층성에 대해 설명해 주세요.
캐시 메모리는 cpu와 메모리의 속도 차이를 완화하기 위해 메모리의 데이터를 미리 가져와 임시로 저장하는 장소입니다. 메모리 계층성은 cpu와 가까울수록 속도는 빠르지만 용량이 작고
하드디스크와 가까울수록 속도는 느리지만 용량은 커서 메모리를 효율적으로 관리할 수 있도록 한 것입니다. cpu에 가까운 쪽으로 레지스터, 캐시, 메모리, 하드디스크 순서로 존재하고 있습니다.

#### ❓ 캐시 메모리는 어디에 위치해 있나요?
캐시 메모리는 cpu와 메모리 사이에 존재하고 있습니다.

#### ❓ L1, L2 캐시에 대해 설명해 주세요.
L1은 cpu 내부에 존재하며 가장 먼저 참조되어 가장 빠른 캐시입니다. 명령어 캐시와 데이터 캐시가 있습니다.
L2는 L1에서 데이터를 찾지 못하면 참조되는 캐시입니다. L1보다는 속도는 느리고 크기는 큽니다. 

#### ❓ 캐시에 올라오는 데이터는 어떻게 관리되나요?
캐시에 올라오는 데이터는 CPU가 메모리 데이터를 요청할 때, 해당 데이터가 캐시에 없으면(CACHE MISS) 메인 메모리에서 불러와 캐시에 저장하면서 동시에 CPU가 사용합니다. 
이후 같은 데이터에 접근할 경우(CACHE HIT), 캐시에서 직접 읽어오므로 성능이 향상됩니다. 캐시가 가득 찬 경우 어떤 데이터를 제거할지는 교체 정책에 따라 결정되며, 
가장 많이 쓰이는 방식으로는 LRU(Least Recently Used), FIFO(First-In First-Out) 등이 있습니다. CPU가 데이터를 변경할 때 메모리에 즉시 반영할지 여부는 쓰기 정책에 따라 달라지며, write-through는 캐시와 메모리에 동시에 반영하는 방식이고, write-back은 캐시에만 먼저 반영하고 나중에 메모리에 반영하는 방식입니다.

#### ❓ 캐시간의 동기화는 어떻게 이루어지나요?
캐시 일관성을 유지하기 위해 캐시간의 동기화는 주로 캐시 일관성 프로토콜을 통해 이루어집니다. 
MESI 프로토콜 캐시에 저장된 데이터 상태를 Modified(수정됨), Exclusive(단독 소유), Shared(공유), Invalid(무효) 중 하나로 관리합니다. 
한 코어가 데이터를 수정하면, 다른 캐시에 해당 데이터는 무효화 상태로 전환해 사용할 수 없게 합니다. 

#### ❓ 캐시 메모리의 Mapping 방식에 대해 설명해 주세요.
캐시 메모리는 CPU가 데이터를 빠르게 찾을 수 있도록 직접 매핑(DIrect Mapping), 완전 연관 매핑(Fully Associative), 집합 연관 매핑 (Set-Associative) 방식으로 매핑됩니다. 
- 직접 매핑: 메인 메모리를 일정한 크기의 블록으로 나누어 각각의 블록을 캐시의 저장된 위치에 매핑하는 것입니다. 간단하지만 적중률이 낮을 수 있습니다.
- 완전 연관 매핑: 캐시 메모리의 빈 공간에 마음대로 주소를 저장하는 방식입니다. 저장하는 것은 간단하지만 원하는 데이터를 찾기 위한 과정에서 비용이 발생합니다.
- 집합 매핑: 빈 공간에 저장하되, 정해둔 특정 행에 저장하는 방식입니다. 직접 매핑과 완전 연관 매핑의 장점을 결합한 방식입니다.

#### ❓ 캐시의 지역성에 대해 설명해 주세요.
공간 지역성은 최근에 사용했던 데이터와 인접한 데이터가 참조될 가능성이 높다는 특성입니다. 예를 들어 코드에서 5행이 실행되었다면 다음에는 6행이 실행될 확률이 높다는 것을 의미합니다.
시간 지역성은 최근에 사용했던 데이터가 재참조될 가능성이 높다는 특성입니다. for문이나 while문에서 사용된 변수는 다시 사용될 가능성이 높습니다. 
캐시의 지역성을 활용해서 캐시의 적중률을 높일 수 있습니다.

#### ❓ 캐시의 지역성을 기반으로, 이차원 배열을 가로/세로로 탐색했을 때의 성능 차이에 대해 설명해 주세요.
이차원배열을 가로로 조회했을 때 공간상의 이점을 활용할 수 있기 때문에 세로로 탐색하는 것보다 성능이 좋습니다. 
가로로 이차원 배열을 탐색할 때, 한 행의 원소들은 메모리에 연속적으로 저장되어 있기때문입니다. 
캐시의 공간 지역성을 활용하여 현재 행의 데이터를 캐시에 미리 로드하면 이후의 참조가 빠르게 이루어집니다.

#### ❓ 캐시의 공간 지역성은 어떻게 구현될 수 있을까요? (힌트: 캐시는 어떤 단위로 저장되고 관리될까요?)
캐시는 메모리의 데이터를 캐시 라인(Cache Line) 단위로 가져와 저장합니다. 
어떤 주소에 접근할 때 그 주소가 속한 캐시라인 전체를 가져와서, 이후 접근 시 캐시에 이미 존재하도록 합니다.

---

### 🔍  15. 메모리의 연속할당 방식 세 가지를 설명해주세요. (first-fit, best-fit, worst-fit)
- first-fit: 가용 공간 중 할당할 수 있는 곳을 찾으면 바로 할당하는 방식입니다. 시간적인 측면에서 효율적이지만 내부 단편화가 발생합니다.
- best-fit: 가용 공간 중 내부 단편화가 가장 적은 곳에 할당하는 방식입나다. 메모리를 가장 효율적으로 사용할 수 있지만 할당할 곳을 찾는 데 오버헤드가 발생합니다.
- worst-fit: 가용 공간 중 가장 큰 곳에 할당하는 방식입니다. 가장 큰 공간을 찾기에 오버헤드가 발생합니다.

#### ❓ worst-fit 은 언제 사용할 수 있을까요?
메모리가 큰 프로그램을 할당해야할 때 효율적입니다.

#### ❓ 성능이 가장 좋은 알고리즘은 무엇일까요?
시간적인 측면에서는 first-fit이 제일 좋고 공간적인 측면에서는b best-fit이 제일 좋습니다.
