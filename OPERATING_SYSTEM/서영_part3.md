### 🔍 16. Thrashing 이란 무엇인가요?
스레싱은 페이지 부재율이 증가하여 CPU 이용률이 급격하게 떨어지는 상황을 의미합니다. 
운영체제는 CPU 이용률이 앉으면 메모리에 동시에 올라가는 프로세스 수를 늘리게 되는데 프로세스가 많아질수록 각 프로세스에 할당된 프레임들은 더욱 적어집니다. 
너무 적은 프레임을 할당받은 프로세스는 페이지 부재가 증가하게되어 페이지 교체가 진행되고 결국 CPU 이용률이 더욱 떨어지게 되는 악순환이 생깁니다.

#### ❓ Thrashing 발생 시, 어떻게 완화할 수 있을까요?
Working Set 알고리즘과 PFF 알고리즘이 있습니다. 
Working Set은 지역성의 원리를 이용해서 지역성 집합이 동시에 메모리에 올라갈 수 있도록 보장하는 방법입니다. 
워킹셋을 구성하는 페이지들이 한꺼번에 올라갈 메모리 공간이 없다면 기존 메모리에 존재하는 페이지는 디스크로 스왑 아웃시켜 동작합니다.

PFF(Page Fault Frequency)는 프로세스의 페이지 부재율을 주기적으로 조사하고 이에 따라 각 프로세스에 할당할 메모리 양을 동적으로 예측하고 조절하는 알고리즘입니다. 
시스템이 미리 정해 놓은 상한값과 하한값을 기준으로 메모리에 올라가 있는 프로세스의 수를 조절하게 됩니다.

---
### 🔍 17. 가상 메모리란 무엇인가요?
운영체제가 실제 물리 메모리(RAM)보다 더 큰 메모리를 사용하는 것처럼 프로그램을 실행할 수 있게 해주는 기술입니다. 
물리 메모리가 부족할 경우, 디스크 공간 일부를 메모리처럼 사용합니다. 따라서 메모리 부족 문제를 해결할 수 있습니다.

#### ❓ 가상 메모리가 가능한 이유가 무엇일까요?
물리 메모리의 내용중 일부를 하드디스크의 일부 공간, 즉 스왑 영역으로 옮기기 때문이다. 스왑 영역은 하드디스크에 존재하지만 메모리 관리자가 관리하는 영역입니다. 
물리 메모리의 부족한 영역을 스왑 영역으로 보충합니다.

#### ❓ Page Fault가 발생했을 때, 어떻게 처리하는지 설명해 주세요.
페이지 폴트는 프로세스가 페이지를 요청했을 때 그 페이지가 실제 메모리에 없는 상황을 말합니다.
페이지 부재가 발생하면 프로세스가 해당 페이지를 사용할 수 있도록 스왑 영역에서 물리 메모리로 옮겨야합니다.
메모리 페이지 중 하나를 대상 페이지(스왑 영역으로 보낼 페이지)를 스왑 영역으로 내보내고 스왑 영역에 있던 페이지가 실제 메모리로 올라간다. 

#### ❓ 페이지 크기에 대한 Trade-Off를 설명해 주세요.
페이지 크기가 커지면 페이지 테이블 엔트리 수가 적어지기 때문에 페이지 테이블 크기가 작아지고 페이지 매핑과 전환에 필요한 시간이 감소합니다. 
하지만 내부 단편화가 증가할 수 있고 작은 데이터 처리에는 비효율적입니다. 
반면 페이지 크기가 작으면 내부 단편화는 줄어들고 데이터 접근 시 불필요한 데이터를 가져오는 비용이 감소합니다. 
대신 테이블 크키가 커지고 페이지 폴트 빈도가 증가합니다.

#### ❓ 페이지 크기가 커지면, 페이지 폴트가 더 많이 발생한다고 할 수 있나요?
페이지 크기가 커질수록 페이지 폴트는 더 적게 발생할 가능성이 있습니다. 
하지만 각 페이지는 쓰이지 않는 코드를 더 많이 포함하게 되기때문에 불필요한 데이터를 가져오는 비용이 증가하고 내부 단편화가 발생할 수 있기 때문에 비효율적입니다. 
꼭 페이지 폴트가 더 적게 발생하는 것은 아니며 프로그램이 불규칙하게 여기저기 데이터에 접근하는 경우 페이지 폴트가 증가할 수 있습니다. 

#### ❓ 세그멘테이션 방식을 사용하고 있다면, 가상 메모리를 사용할 수 없을까요?
세그멘테이션 매핑 테이블을 이용해서 가상 메모리를 사용할 수 있습니다. 하지만 외부 단편화가 발생할 수 있고 주소 변환이 페이징보다 복잡하다는 단점이 있습니다.
대부분은 페이징 또는 페이징과 세그멘테이션을 혼합해서 사용하고 있습니다.

---
### 🔍 18. 세그멘테이션과 페이징의 차이점은 무엇인가요?
세그멘테이션은 메모리를 프로세스의 크기에 맞게 자르는 것이고 페이징은 메모리를 같은 크기로 자르는 것입니다. 
세그멘테이션은 외부 단편화가 발생하고 페이징은 내부 단편화가 발생합니다. 
또한 세그멘테이션 가변 분할 방식이기 때무에 복잡한 메모리 할당 알고리즘이 필요한데 페이징은 단순하고 효율적으로 구현 가능합니다.

#### ❓ 페이지와 프레임의 차이에 대해 설명해 주세요.
페이지는 가상 메모리를 분할 단위이고 프레임은 물리 메모리(RAM)의 분할 단위입니다.

#### ❓ 내부 단편화와, 외부 단편화에 대해 설명해 주세요.
내부 단편화(internal fragmentation): 프로그램 크기보다 분할의 크기가 큰 경우 해당 분할에 프로그램을 적재하고 남는 현상
외부 단편화(external fragmentation): 프로그램 크기가 분할의 크기보다 커서 해당 분할이 비어있는데도 프로그램을 적재하지 못하는 현상

#### ❓ 페이지에서 실제 주소를 어떻게 가져올 수 있는지 설명해 주세요.
가상 주소의 페이지 번호로 페이지 테이블에서 해당하는 프레임 번호를 얻습니다. 프레임 번호와 페이지 크기를 곱하고 페이지 오프셋을 더해 실제 주소를 계산합니다.

#### ❓ 어떤 주소공간이 있을 때, 이 공간이 수정 가능한지 확인할 수 있는 방법이 있나요?
있습니다. 페이지 테이블 엔트리에는 보호 비트가 있습니다. 보호 비트가 1이면 읽기만 가능한 페이지며, 0이면 읽기와 쓰기가 모두 가능한 페이지라는 뜻입니다. 

#### ❓ 32비트에서, 페이지의 크기가 1kb 이라면 페이지 테이블의 최대 크기는 몇 개일까요?
32비트 시스템에서 4GB 주소공간을 갖고 있습니다. 이 때 페이지 크기는 1kb로 한 페이지에는 2^10 바이트의 데이터가 들어갈 수 있습니다.  
2^32 / 2^10 총 2^22개를 가질 수 있습니다.

#### ❓ 32비트 운영체제는 램을 최대 4G 까지 사용할 수 있습니다. 이 이유를 페이징과 연관 지어서 설명해 주세요.
32비트 운영체제는 하나의 주소를 32비트 이진수로 표현하는데 2^32 즉 4GB 만큼의 주소 공간만을 가질 수 잇습니다.
주소 공간이 4GB로 제한되어 있기 때문에 가상 주소를 물리 주소로 변환하는 페이징 구조에서도 4GB를 넘는 메모리를 표현할 수 없고 RAM도 최대 4GB까지만 사용할 수 있습니다.

#### ❓ C/C++ 개발을 하게 되면 Segmentation Fault 라는 에러를 접할 수 있을텐데, 이 에러는 세그멘테이션/페이징과 어떤 관계가 있을까요?
Segmentation Fault는 사용자 프로세스가 주어진 메모리 공간을 벗어나거나 접근 권한이 없는 곳에 접근할 때 발생합니다. 
세그멘테이션에서는 세그먼트의 유효 범위를 벗어난 접근, 페이징에서는 페이지 테이블에 없는 주소 접근이나 권한이 없는 접근이 그 원인이 됩니다.
예를 들어 null pointer에 접근할 때 해당 주소는 페이지 테이블에 없기 때문에 segementation fault가 발생합니다. 


---
### 🔍 19. TLB는 무엇인가요?
가상 메모리 주소를 물리적 주소르 변환하는 속도를 높이기 위해서 사용하는 캐시입니다. 
CPU가 가상 주소로 메모리에 접근하려고 할 때, 먼저 TLB에 접근 후 없으면 페이지 테이블에서 찾습니다.

#### ❓ TLB를 쓰면 왜 빨라지나요?
메모리에 접근하는 것이 아니라 cpu에 탑재된 MMU 내부에서 물리 주소를 얻을 수 있기 때문입니다.

#### ❓ MMU가 무엇인가요?
메모리 관리 장치 MMU(Memory Management Unit)는 가상 주소를 물리 주소로 변환해주는 역할을 합니다. CPU 내부에 있기때문에 빠르게 작업할 수 있습니다.

#### ❓ TLB와 MMU는 어디에 위치해 있나요?
TLB와 MMU 모두 CPU 내부에 위치합니다. TLB는 MMU 내부에 위치며 가상 주소와 실제 물리 주소 간의 변환 정보를 저장하고 검색합니다. 
MMU는 CPU 내부의 하드웨어로, 주소 변환을 수행하여 가상 주소를 실제 물리 주소로 변환합니다.

#### ❓ 코어가 여러개라면, TLB는 어떻게 동기화 할 수 있을까요?
TLB를 무효화하는 TLB shootdown을 통해 동기화할 수 있습니다.
TLB shootdown은 한 코어가 페이지 테이블 변경 시 다른 코어에게 TLB를 무효화라고 신호를 보내는 매커니즘입니다. 

#### ❓ TLB 관점에서, Context Switching 발생 시 어떤 변화가 발생하는지 설명해 주세요
이전 프로세스의 주소 변환 정보를 담고 있는 내용이 전부 지워집니다.

---
### 🔍 20. 동기화를 구현하기 위한 하드웨어적인 해결 방법에 대해 설명해 주세요.
메모리 장벽과 잠금 명령어를 사용하는 방법이 있습니다. CPU는 명령어 최적화를 위해 명령어를 재정렬할 수 있습니다. 메모리 장벽은 하드웨어적으로 명령어 실행 순서를 강제하여 동기화된 실행 순서가 보장되도록 합니다. 
또는 Test And Set이나 Compare and Swap 명령어를 사용해서 세마포어나 뮤텍스와 같은 동기화 기법을 하드웨어적으로 지원하는 방식입니다.

#### ❓ volatile 키워드는 어떤 의미가 있나요?
volatile 키워드는 cpu 캐시가 아닌 메인 메모리에서 항상 변수를 읽고 쓰도록 보장하는 키워드입니다. 이 키워드를 통해서 멀티스레드 환경에서도 공유 변수의 일관성을 유지할 수 있습니다. 변수 변경이 즉시 다른 스레드에 반영되기 때문에 쓰레드 종료를 제어하는 플래그 변수에서 사용할 수 있습니다. 다만 원자성이 보장되지 않기때문에 복합 연산에는 적합하지 않습니다.

#### ❓ 싱글코어가 아니라 멀티코어라면, 어떻게 동기화가 이뤄질까요?
캐시 일관성 유지를 위해 캐시 일관성 프로토콜을 사용할 수 있습니다. 하드웨어 락을 걸어 동일 자원에 접근하는 것을 막을 수도 있고 메모리 장벽을 사용해 동기화된 실행 순서를 보장할 수 있습니다.

---
### 🔍 21. 페이지 교체 알고리즘에 대해 설명해 주세요.
메인 메모리가 가득 찼을 때 어떤 페이지를 제거할지 결정하는 알고리즘입니다. 대표적으로는 FIFO, LRU, LFU 알고리즘이 있습니다. FIFO는 메모리에 가장 먼저 들어온 페이지를 제거합니다. LRU는 사용한 지 가장 오래된 페이지를 제거합니다. LFU는 가장 적게 사용한 페이지를 제거합니다. 

#### ❓ LRU 알고리즘은 어떤 특성을 이용한 알고리즘이라고 할 수 있을까요?
시간 지역성을 이용한 알고리즘이라고 할 수 있습니다. LRU 알고리즘은 가장 오랫동안 사용하지 않은 페이지를 제거하는 방법입니다. 최근 사용된 페이지는 다시 사용될 가능성이 높기 때문에 오래된 페이지를 제거하는 방법이므로 시간 지역성을 이용한 알고리즘입니다.

#### ❓ LRU 알고리즘을 구현한다면, 어떻게 구현할 수 있을까요?
해시맵과 이중 연결 리스트를 조합하여 구현할 수 있습니다. 해시맵을 이용해 키로 빠르게 노드를 찾을 수 있습니다. 이중 연결 리스트는 사용 순서를 유지하며 가장 오래된 데이터를 빠르게 제거할 수 있습니다.

#### ❓ LRU 알고리즘의 단점을 설명해 주세요. 이를 해결할 수 있는 대안에 대해서도 설명해 주세요.
페이지를 참조할 때마다 순서를 업데이트하므로 큰 비용이 발생합니다. 이는 Clock 알고리즘으로 보완할 수 있습니다. 이 알고리즘은 최근에 사용하지 않은 페이지를 제거합니다. 이는 참조 비트를 통해 가능합니다. 페이지 참조시 참조 비트를 1로 설정하고 페이지 부재 발생했을 때 포인터가 가리키는 페이지의 참조 비트가 0인 것을 제거합니다. 만약 1인 경우는 0으로 만들고 지나가기 때문에 최근에 사용했더라도 제거될 수 있다는 단점이 있습니다.

---
### 🔍 22. File Descriptor와, File System에 에 대해 설명해 주세요.
File Descriptor는 운영체제가 열린 파일이나 소켓 등을 식별하기 위해 부여하는 정수 ID입니다. 프로세스가 실행 중에 파일을 열면 해당 프로세스의 file descriptor 숫자 중에 사용하지 않는 가장 작은 값을 할당해줍니다. 이 값을 통해 파일에 접근할 수 있습니다.
File System은 파일을 조직적으로 저장하는 구조이며 이를 통해 컴퓨터에서 파일을 쉽게 찾을 수 있습니다. 파일 시스템은 파일의 데이터가 저장된 메타 영역, 실제 데이터가 기록된 데이터 영역으로 나뉩니다.

#### ❓ I-Node가 무엇인가요?
유닉스 계열에서 파일 시스템을 관리하기 위해 사용하는 것으로 파일 정보를 가지고 있습니다. 파일은 실제 데이터와 파일 속성으로 구성되어 있는데 I-Node는 파일 속성을 가리키는 값입니다. 파일 속성에는 I-Node number, 파일 타입, 접근 권한과 같은 정보가 담겨있습니다.

#### ❓ 프로그래밍 언어 상에서 제공하는 파일 관련 함수 (Python - open(), Java - BufferedReader/Writer 등)은, 파일을 어떤 방식으로 읽어들이나요?
자바에서 파일을 읽을 때, BufferedReader는 운영체제의 read() 시스템 콜로 연결되어 있으며, 이 과정에서 File Descriptor가 생성되어 사용됩니다.


---
### 🔍 23. 동기와 비동기, 블로킹과 논블로킹의 차이에 대해 설명해 주세요.
동기/비동기는 작업 완료 여부를 신경쓰는가에 대한 흐름 제어 방식이고 블로킹/논블로킹은 제어권을 어떻게 처리하느야에 대한 제어 방식입니다. 
A함수가 B함수를 호출한다고 가정했을 때,

동기: A함수는 B함수가 종료되었는지 계속 확인합니다.

비동기: A함수는 B함수의 종료 여부를 신경쓰지 않습니다. 호출할 때 콜백함수를 함께 전달해서 B함수의 작업이 완료되면 콜백함수를 실행합니다.

블로킹: A함수가 가지고 있던 제어권을 B함수에게 넘겨줍니다. A함수의 제어권이 없기 때문에 스레드가 멈춥니다. B함수의 실행이 끝나면 제어권은 다시 A함수에게 넘어오고 다시 실행됩니다.

논블로킹: 제어권을 B함수에게 넘기지 않고 A함수가 계속 가지고 있습니다. 제어권은 없지만 B함수는 실행됩니다.

#### ❓ 그렇다면, 동기이면서 논블로킹이고, 비동기이면서 블로킹인 경우는 의미가 있다고 할 수 있나요?
둘 다 가능한 상황이지만 비효율적인 방법이라고 생각합니다.
동기이면서 논블로킹이면 호출한 함수가 제어권을 계속 가지고 있기 때문에 호출한 함수, 호출된 함수가 모두 실행되고 있습니다. 호출된 함수의 리턴값은 필요하기 때문에 반복적으로 상태를 체크하는 polling이 사용되기에 오버헤드가 발생합니다.
비동기이면서 블로킹인 경우는 호출된 쪽으로 제어권을 갖게됩니다. 호출한 함수는 호출된 함수의 결과값이 필요없음에도 불구하고 작업이 끝날때까지 기다려야하기 때문에 비효율적입니다.

#### ❓ I/O 멀티플렉싱에 대해 설명해 주세요.
I/O 멀티플렉싱은 입출력 다중화로 하나의 통신 채널을 통해서 둘 이상의 데이터를 전송하기 위한 기술입니다. 각 파일을 처리할 때마다 개별 프로세스를 만들면 컨텍스트 스위칭 등의 오버헤드가 발생합니다. I/O 멀티 플렉싱을 사용하면 하나의 채널을 통해 여러 데이터를 송/수신하여 프로세스 갯수를 최소한으로 유지할 수 있어 효율적입니다. 

#### ❓ 논블로킹 I/O를 수행한다고 하면, 그 결과를 어떻게 수신할 수 있나요?
I/O 완료를 알리는 이벤트나 콜백을 통해 결과 데이터를 받을 수 있습니다. 
